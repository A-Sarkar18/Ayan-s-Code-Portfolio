{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Hyperparameters using Car Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TprtqAhLn9w8"
   },
   "source": [
    "# Import Data & Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVrKXCk4njhr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the used car prices dataset included in the course package, perform the following:\n",
    "1. Load the “used_car_price.csv” dataset \n",
    "3. Split the data into 75% for training and 25% for testing \n",
    "4. Train an XG-Boost model in Scikit-Learn\n",
    "5. Assess trained XG-Boost model performance using RMSE and R2 \n",
    "6. Perform hyperparameters optimization using GridSearch, choose any reasonable values for max_depth, learning_rate, n_estimators, and colsample_bytree. Use 5 cross validation folds.  \n",
    "7. Perform hyperparameters optimization using RandomSearch, choose any reasonable values for max_depth, learning_rate, n_estimators, and colsample_bytree. Use 5 cross validation folds and 100 iterations.  \n",
    "8. Compare the optimization strategies using RMSE and R2. Feel free to introduce any additional optimization strategy. Comment on your resuk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Optimization Using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file \n",
    "car_df = pd.read_csv(\"used_car_price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Origin</th>\n",
       "      <th>DriveTrain</th>\n",
       "      <th>MSRP</th>\n",
       "      <th>EngineSize</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>MPG_City</th>\n",
       "      <th>MPG_Highway</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>MDX</td>\n",
       "      <td>SUV</td>\n",
       "      <td>Asia</td>\n",
       "      <td>All</td>\n",
       "      <td>36945</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>265</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>4451</td>\n",
       "      <td>106</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acura</td>\n",
       "      <td>RSX Type S 2dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>23820</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>2778</td>\n",
       "      <td>101</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Acura</td>\n",
       "      <td>TSX 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>26990</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>22</td>\n",
       "      <td>29</td>\n",
       "      <td>3230</td>\n",
       "      <td>105</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acura</td>\n",
       "      <td>TL 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>33195</td>\n",
       "      <td>3.2</td>\n",
       "      <td>6</td>\n",
       "      <td>270</td>\n",
       "      <td>20</td>\n",
       "      <td>28</td>\n",
       "      <td>3575</td>\n",
       "      <td>108</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Acura</td>\n",
       "      <td>3.5 RL 4dr</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Asia</td>\n",
       "      <td>Front</td>\n",
       "      <td>43755</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6</td>\n",
       "      <td>225</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>3880</td>\n",
       "      <td>115</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Make           Model   Type Origin DriveTrain   MSRP  EngineSize  \\\n",
       "0  Acura             MDX    SUV   Asia        All  36945         3.5   \n",
       "1  Acura  RSX Type S 2dr  Sedan   Asia      Front  23820         2.0   \n",
       "2  Acura         TSX 4dr  Sedan   Asia      Front  26990         2.4   \n",
       "3  Acura          TL 4dr  Sedan   Asia      Front  33195         3.2   \n",
       "4  Acura      3.5 RL 4dr  Sedan   Asia      Front  43755         3.5   \n",
       "\n",
       "   Cylinders  Horsepower  MPG_City  MPG_Highway  Weight  Wheelbase  Length  \n",
       "0          6         265        17           23    4451        106     189  \n",
       "1          4         200        24           31    2778        101     172  \n",
       "2          4         200        22           29    3230        105     183  \n",
       "3          6         270        20           28    3575        108     186  \n",
       "4          6         225        18           24    3880        115     197  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the top 5 instances\n",
    "car_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform One-Hot Encoding to create dummies for \"Make\", \"Model\", \"Type\", \"Origin\", and \"DriveTrain\"\n",
    "car_df = pd.get_dummies(car_df, columns=[\"Make\", \"Model\", \"Type\", \"Origin\", \"DriveTrain\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding input features to X and output (MSRP) to y\n",
    "X = car_df.drop(\"MSRP\", axis = 1)\n",
    "y = car_df[\"MSRP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create test data using 25% from sample\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  3.2,   6. , 215. , ...,   0. ,   0. ,   1. ],\n",
       "       [  2.2,   4. , 140. , ...,   0. ,   1. ,   0. ],\n",
       "       [  3.2,   6. , 290. , ...,   0. ,   0. ,   1. ],\n",
       "       ...,\n",
       "       [  2.6,   6. , 168. , ...,   1. ,   0. ,   0. ],\n",
       "       [  6.8,  10. , 310. , ...,   1. ,   0. ,   0. ],\n",
       "       [  3.2,   6. , 221. , ...,   0. ,   0. ,   1. ]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.7,   8. , 235. , ...,   1. ,   0. ,   0. ],\n",
       "       [  2.4,   4. , 150. , ...,   0. ,   1. ,   0. ],\n",
       "       [  4.6,   8. , 224. , ...,   0. ,   0. ,   1. ],\n",
       "       ...,\n",
       "       [  4.3,   8. , 300. , ...,   0. ,   0. ,   1. ],\n",
       "       [  3. ,   6. , 225. , ...,   0. ,   0. ,   1. ],\n",
       "       [  3. ,   6. , 220. , ...,   0. ,   1. ,   0. ]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/ayansarkar/anaconda3/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in /Users/ayansarkar/anaconda3/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in /Users/ayansarkar/anaconda3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "RMSE = 8540.773 \n",
      "R2 = 0.7953782827504423\n"
     ]
    }
   ],
   "source": [
    "#Using just core XGBoost to estimate a prediction.\n",
    "!pip install xgboost\n",
    "import xgboost as xgb\n",
    "model = xgb.XGBRegressor(objective ='reg:squarederror', learning_rate = 1, max_depth = 3, n_estimators = 500)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data using the text regressors\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "\n",
    "#Assess Model Performance\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-47875344.185 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-227604528.843 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-28767924.871 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-44624157.233 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-54761345.646 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-44902549.329 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-214404414.393 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-26147567.319 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-39064438.524 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-49798620.545 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-59893657.500 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-235119394.420 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-32946069.082 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-47848973.334 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-71289919.561 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-59403604.555 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-234391323.017 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-32810138.008 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-47514171.899 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-71147481.075 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-59166753.025 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-238458726.041 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-39267011.263 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-49679344.081 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-79269559.874 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-59076644.366 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-238177898.426 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-39168604.267 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-49650825.057 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-79121292.982 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-41668932.065 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-220440800.036 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-35508270.192 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-52650515.543 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-86929245.134 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-40420594.893 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-218057416.166 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-34951420.965 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-51473357.674 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-86546113.698 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-72999788.237 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-289212180.554 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-56307530.803 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-89477881.987 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-176663379.729 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-73012225.610 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-289131144.094 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-56305660.573 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-89471205.412 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-176608125.992 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-66398899.283 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-263691586.673 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-77051716.170 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-83418262.912 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-183604566.892 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-66399059.094 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-263691668.420 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-77051744.165 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-83418176.152 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.3, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-183604495.583 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-55454181.872 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-207261927.199 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-30187562.509 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-43900753.154 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100;, score=-64102231.494 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-52302235.565 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-191114055.286 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-28721392.764 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-40838863.374 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=500;, score=-61595591.893 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-58609893.790 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-231586336.805 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-32925129.161 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-63774317.491 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=100;, score=-52636832.604 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-58465495.841 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-231143103.780 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-32610615.722 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-63742269.328 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=10, n_estimators=500;, score=-52933170.314 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-61509742.039 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-232260000.349 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-32023682.577 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-67017470.019 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=100;, score=-53398677.544 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-61494550.872 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-231997222.735 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-31995180.649 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-67008775.269 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.1, max_depth=20, n_estimators=500;, score=-53758216.340 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-69249331.551 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-221611919.089 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-35755007.385 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-41253912.400 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=100;, score=-82318323.537 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-67864769.705 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-217921758.477 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-35201724.084 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-40046975.403 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=3, n_estimators=500;, score=-83420077.101 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-71785093.196 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-246304974.017 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-37443677.921 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-58939619.826 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=100;, score=-69481697.384 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-71773587.457 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-246299822.945 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-37440726.735 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-58926672.879 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=10, n_estimators=500;, score=-69478426.623 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-76372040.934 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-246051717.442 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-37778421.440 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-63998129.926 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=100;, score=-70152936.298 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-76372046.354 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-246051712.862 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-37778440.115 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-63998164.734 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.7, learning_rate=0.5, max_depth=20, n_estimators=500;, score=-70152953.729 total time=   0.9s\n",
      "RMSE = 5445.641 \n",
      "R2 = 0.9168130218895394\n"
     ]
    }
   ],
   "source": [
    "#Use XG-Boost with Gridsearch to optimize estimate\n",
    "#Use 5 cross validation folds and 100 iterations\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Select parameters\n",
    "parameters_grid = { 'max_depth': [3, 10, 20], \n",
    "                   'learning_rate': [0.1, 0.5],\n",
    "                   'n_estimators': [100, 500],\n",
    "                   'colsample_bytree': [0.3, 0.7]}\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "\n",
    "#\"neg_mean_squared_error\" ranks all the estimators and specifies which one is the best to minimize the error.  \n",
    "xgb_gridsearch = GridSearchCV(estimator = model, \n",
    "                              param_grid = parameters_grid, \n",
    "                              scoring = 'neg_mean_squared_error',  \n",
    "                              cv = 5, \n",
    "                              verbose = 5)\n",
    "\n",
    "xgb_gridsearch.fit(X_train, y_train)\n",
    "y_predict = xgb_gridsearch.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "#Assess Model Performance\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, y_predict)),'.3f'))\n",
    "r2 = r2_score(y_test, y_predict)\n",
    "\n",
    "print('RMSE =',RMSE,'\\nR2 =', r2) \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Retail Sales Forecast.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
